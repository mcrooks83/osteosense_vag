{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "681ba41f-51e8-4cdd-a3e8-9ecb83ac5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import statistics as stats\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from scipy.signal import medfilt, butter, filtfilt, lfilter, find_peaks, find_peaks_cwt,resample, detrend\n",
    "from scipy.signal import welch, spectrogram, get_window\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e208e-5399-49bf-bc13-43b105fceb0b",
   "metadata": {},
   "source": [
    "Goal is to create a feature set consisting of\n",
    "\n",
    "1. Fractal dimension\n",
    "2. VMS\n",
    "3. LI\n",
    "\n",
    "OUTPUT: A csv file of the features with 0 for normal and 1 for pathological\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26aa3bd3-e651-4b59-b274-7ddbde641b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 normal subjects\n",
      "38 pathology subjects\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/open_vag/normal/novag1\"\n",
    "normal_dir = \"../data/open_vag/normal/\"\n",
    "pathology_dir = \"../data/open_vag/pathology/\"\n",
    "\n",
    "normal_vag_subjects = [] # 51\n",
    "pathology_vag_subjects = [] # 38\n",
    "\n",
    "# read all the files in the normal folder\n",
    "novag_base_f = \"novag\"\n",
    "ab_base_f  = \"abvag\"\n",
    "\n",
    "# read normal files\n",
    "for i, filename in enumerate(os.listdir(normal_dir)):\n",
    "    file_path = os.path.join(normal_dir, f\"{novag_base_f}{i+1}\")\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read all the floating-point numbers into a list\n",
    "        vags = [float(x) for x in file.read().split()]\n",
    "        normal_vag_subjects.append(vags)\n",
    "        \n",
    "# read pathology files\n",
    "for i, filename in enumerate(os.listdir(pathology_dir)):\n",
    "    file_path = os.path.join(pathology_dir, f\"{ab_base_f}{i+1}\")\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read all the floating-point numbers into a list\n",
    "        p_vags = [float(x) for x in file.read().split()]\n",
    "        pathology_vag_subjects.append(p_vags)\n",
    "\n",
    "print(f\"{len(normal_vag_subjects)} normal subjects\")\n",
    "print(f\"{len(pathology_vag_subjects)} pathology subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8860193-e577-4b32-955b-4b2bd01568c6",
   "metadata": {},
   "source": [
    "First step is to normalise, resample and split the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c94bd4c2-f8d6-41be-b77d-568614108e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192 4096 4096\n",
      "[array([0.64705882, 0.68894522, 0.67651567, ..., 0.20224812, 0.18061191,\n",
      "       0.20832206]), array([0.19037075, 0.19525017, 0.1754564 , ..., 0.65249042, 0.647611  ,\n",
      "       0.65359477])]\n"
     ]
    }
   ],
   "source": [
    "def amplitude_normal(signal):\n",
    "    sig = np.array(signal)\n",
    "    data_min = min(sig)\n",
    "    data_max = max(sig)\n",
    "    normal = (sig - data_min) / (data_max - data_min)\n",
    "    return normal.tolist()\n",
    "\n",
    "def resample_signal(signal, points, fs):\n",
    "    t = np.linspace(0, fs, num=len(signal))\n",
    "    x_new = np.linspace(t.min(), t.max(), points)\n",
    "    interpolator = interp1d(t, signal, kind='linear')\n",
    "    y_new = interpolator(x_new)\n",
    "    return y_new\n",
    "\n",
    "def split_signal(signal):\n",
    "    middle = len(signal) // 2\n",
    "    # Split the array into two halves\n",
    "    first_half = signal[:middle]\n",
    "    second_half = signal[middle:]\n",
    "    \n",
    "    return [first_half, second_half]\n",
    "\n",
    "\n",
    "r_l = 8192\n",
    "fs = 2000 # 2khz sampling rate\n",
    "\n",
    "n_res = [] # resampled normal vag signal\n",
    "n_ext_flex = [] # resampled split vag signal\n",
    "p_res = [] # resampled normal pathological signal\n",
    "p_ext_flex = [] # resampled split pathological signal\n",
    "\n",
    "for d_set in normal_vag_subjects:\n",
    "    n = amplitude_normal(d_set)\n",
    "    n_resampled = resample_signal(n, r_l, fs)\n",
    "    n_res.append(n_resampled)\n",
    "\n",
    "    # split into extension / flexion\n",
    "    ext_flex = split_signal(n_resampled)  # ext is 0 and flex is 1\n",
    "    n_ext_flex.append(ext_flex)\n",
    "\n",
    "for d_set in pathology_vag_subjects:\n",
    "    p = amplitude_normal(d_set)\n",
    "    p_resampled = resample_signal(p, r_l, fs)\n",
    "    p_res.append(p_resampled)\n",
    "\n",
    "    # split into extension / flexion\n",
    "    ext_flex = split_signal(p_resampled)  # ext is 0 and flex is 1\n",
    "    p_ext_flex.append(ext_flex)\n",
    "\n",
    "print(len(n_res[0]), len(n_ext_flex[0][0]), len(n_ext_flex[0][1]))\n",
    "\n",
    "print(n_ext_flex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18db26e2-56d0-4d0c-b433-daca79e51cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "avg fd normal: 1.8231458599028687 +/- 0.2343\n",
      "avg fd pathol: 1.6857154278161657 +/- 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111654/2221893466.py:32: RuntimeWarning: divide by zero encountered in log10\n",
      "  s_log_f = np.log10(s_x)\n",
      "/tmp/ipykernel_111654/2221893466.py:32: RuntimeWarning: invalid value encountered in log10\n",
      "  s_log_f = np.log10(s_x)\n"
     ]
    }
   ],
   "source": [
    "# compute the fractal dimension of each signal \n",
    "\n",
    "def apply_hanning(d):\n",
    "    hanning_window = np.hanning(len(d))\n",
    "    windowed_signal = d * hanning_window\n",
    "    return windowed_signal\n",
    "\n",
    "# assumes len(data) is a fft multiple i.e 4096 or 8192\n",
    "def compute_fft_mag(data):\n",
    "    fftpoints = len(data) #int(math.pow(2, math.ceil(math.log2(len(data)))))\n",
    "    fft = np.fft.fft(data, n=fftpoints)\n",
    "    mag = np.abs(fft) #/ (fftpoints/2)\n",
    "    return mag\n",
    "\n",
    "# assumes a numpy arrray\n",
    "def compute_power_spectrum(fft_mag):\n",
    "    power = np.square(fft_mag)\n",
    "    return power\n",
    "    \n",
    "def compute_fd(slope):\n",
    "    fd = (5 - abs(slope)) / 2\n",
    "    return fd\n",
    "\n",
    "def vag_to_fd(s):\n",
    "    s_han = apply_hanning(s)\n",
    "    #compute fft and power spectrum\n",
    "    s_fft = compute_fft_mag(s_han)\n",
    "    s_pwr = compute_power_spectrum(s_fft)\n",
    "    # get the frequency axis\n",
    "    s_x = np.fft.fftfreq(len(s), d=1/fs)\n",
    "    # compute the log log\n",
    "    s_log_f = np.log10(s_x)\n",
    "    s_log_pwr = np.log10(s_pwr)\n",
    "\n",
    "    indices = np.where((s_x > 10) & (s_x < 300))[0]\n",
    "    x = s_log_f[indices]\n",
    "    y = s_log_pwr[indices]\n",
    "    m, b, r_value, p_value, std_err = linregress(x, y)\n",
    "    # we only care about the slope for fd\n",
    "    s_fd = compute_fd(m)\n",
    "    return s_fd\n",
    "\n",
    "# frequency range to compute fd (Hz)\n",
    "min_f = 10  \n",
    "max_f = 300\n",
    "\n",
    "n_fd = []\n",
    "n_ext_flex_fd = []\n",
    "p_fd = []\n",
    "p_ext_flex_fd = []\n",
    "\n",
    "# normal vag signals\n",
    "for i, n in enumerate(n_res):\n",
    "    fd = vag_to_fd(n)\n",
    "    n_fd.append(fd)\n",
    "\n",
    "    # compute fd for extension and flexion\n",
    "    fd_ext = vag_to_fd(n_ext_flex[i][0])\n",
    "    fd_flex = vag_to_fd(n_ext_flex[i][1])\n",
    "    n_ext_flex_fd.append([fd_ext, fd_flex])\n",
    "\n",
    "    # compute for pathological signal\n",
    "    if(i < len(p_res)):\n",
    "        fd = vag_to_fd(p_res[i])\n",
    "        p_fd.append(fd)\n",
    "\n",
    "        fd_ext = vag_to_fd(p_ext_flex[i][0])\n",
    "        fd_flex = vag_to_fd(p_ext_flex[i][1])\n",
    "        p_ext_flex_fd.append([fd_ext, fd_flex])\n",
    "\n",
    "print(len(n_fd), len(p_fd))\n",
    "\n",
    "print(f\"avg fd normal: {float(np.mean(n_fd))} +/- {round(np.std(n_fd),4)}\")\n",
    "print(f\"avg fd pathol: {np.mean(p_fd)} +/- {round(np.std(p_fd),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1c12d-4ee3-4340-b98c-8f8ac5ff8c82",
   "metadata": {},
   "source": [
    "statistically highly signiﬁcant (p < 0.01),\n",
    "statistically signiﬁcant (0.01 < p < 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf328a81-c2e0-448a-896b-f3ff09e03f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD P-value: 0.006544978798828279\n",
      "FD1 P-value: 0.1395773801716729\n",
      "FD2 P-value: 0.05250587609689865\n"
     ]
    }
   ],
   "source": [
    "# test p values for fd\n",
    "# check p values agains the paper - IDENTICAL\n",
    "fd_t, fd_p_value = stats.ttest_ind(n_fd, p_fd)\n",
    "print(\"FD P-value:\", fd_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_fd1 = []\n",
    "p_fd1 = []\n",
    "for r in n_ext_flex_fd:\n",
    "    n_fd1.append(r[0])\n",
    "for r in p_ext_flex_fd:\n",
    "    p_fd1.append(r[0])\n",
    "\n",
    "fd1_t, fd1_p_value = stats.ttest_ind(n_fd1, p_fd1)\n",
    "print(\"FD1 P-value:\", fd1_p_value)\n",
    "\n",
    "n_fd2 = []\n",
    "p_fd2 = []\n",
    "for r in n_ext_flex_fd:\n",
    "    n_fd2.append(r[1])\n",
    "for r in p_ext_flex_fd:\n",
    "    p_fd2.append(r[1])\n",
    "\n",
    "fd2_t, fd2_p_value = stats.ttest_ind(n_fd2, p_fd2)\n",
    "print(\"FD2 P-value:\", fd2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b663abfd-9cdf-4012-a190-3150b51d3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "VMS normal: 0.005753680411507353 +/- 0.0061\n",
      "VMS pathol: 0.012342551934292012 +/- 0.0136\n"
     ]
    }
   ],
   "source": [
    "# compute the VMS -> Mean Squared every 5ms \n",
    "# 2khz and 5ms = 10 samples per block\n",
    "\n",
    "# window in seconds - 0.005 is 5ms fs in Hz \n",
    "def compute_mean_squared_variance(signal, fs, window=0.005):\n",
    "    samples_per_group = int(window * fs)\n",
    "    num_groups = len(signal) // samples_per_group\n",
    "    \n",
    "    # Slice the array to only include full groups\n",
    "    trimmed_array = signal[:num_groups * samples_per_group]\n",
    "    \n",
    "    # Reshape the array into a 2D array where each row is a group of 10 samples\n",
    "    reshaped_array = trimmed_array.reshape(num_groups, samples_per_group)\n",
    "    #mean = np.mean(reshaped_array, axis=1)\n",
    "    mean_squared = [np.mean(row)**2 for row in reshaped_array]\n",
    "    variance = np.var(mean_squared)\n",
    "    \n",
    "    return variance, mean_squared\n",
    "    \n",
    "n_list = []\n",
    "p_list = []\n",
    "n_mean_sqr = []\n",
    "n_mean_sqr_ext_flex = []\n",
    "p_mean_sqr = []\n",
    "p_mean_sqr_ext_flex = []\n",
    "\n",
    "for i, n in enumerate(n_res):\n",
    "    var, n_m_sqr = compute_mean_squared_variance(n, fs)\n",
    "    n_mean_sqr.append(var)\n",
    "    n_list.append(n_m_sqr)\n",
    "    var_ext, n_sqr_ext = compute_mean_squared_variance(n_ext_flex[i][0], fs)\n",
    "    var_flex, n_sqr_flx = compute_mean_squared_variance(n_ext_flex[i][1], fs)\n",
    "    n_mean_sqr_ext_flex.append([var_ext, var_flex])\n",
    "\n",
    "    if(i < len(p_res)):\n",
    "        p_var, p_m_sqr = compute_mean_squared_variance(p_res[i], fs)\n",
    "        p_mean_sqr.append(p_var)\n",
    "        p_list.append(p_m_sqr)\n",
    "    \n",
    "        p_var_ext, p_sqr_ext = compute_mean_squared_variance(p_ext_flex[i][0], fs)\n",
    "        p_var_flex, p_sqr_flx = compute_mean_squared_variance(p_ext_flex[i][1], fs)\n",
    "        p_mean_sqr_ext_flex.append([p_var_ext, p_var_flex])\n",
    "\n",
    "\n",
    "print(len(n_mean_sqr), len(p_mean_sqr))\n",
    "\n",
    "print(f\"VMS normal: {float(np.mean(n_mean_sqr))} +/- {round(np.std(n_mean_sqr),4)}\")\n",
    "print(f\"VMS pathol: {np.mean(p_mean_sqr)} +/- {round(np.std(p_mean_sqr),4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "827f70e7-16ef-4754-9983-3002db7a87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMS P-value: 0.0032695713092980847\n",
      "VMS1 P-value: 0.011796573584033658\n",
      "VMS1 P-value: 0.00326419552579523\n"
     ]
    }
   ],
   "source": [
    "# check p values agains the paper - IDENTICAL\n",
    "vms_t, vms_p_value = stats.ttest_ind(n_mean_sqr, p_mean_sqr)\n",
    "print(\"VMS P-value:\", vms_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_vms1 = []\n",
    "p_vms1 = []\n",
    "for r in n_mean_sqr_ext_flex:\n",
    "    n_vms1.append(r[0])\n",
    "for r in p_mean_sqr_ext_flex:\n",
    "    p_vms1.append(r[0])\n",
    "\n",
    "vms1_t, vms1_p_value = stats.ttest_ind(n_vms1, p_vms1)\n",
    "print(\"VMS1 P-value:\", vms1_p_value)\n",
    "\n",
    "#flextion\n",
    "n_vms2 = []\n",
    "p_vms2 = []\n",
    "for r in n_mean_sqr_ext_flex:\n",
    "    n_vms2.append(r[1])\n",
    "for r in p_mean_sqr_ext_flex:\n",
    "    p_vms2.append(r[1])\n",
    "    \n",
    "vms2_t, vms2_p_value = stats.ttest_ind(n_vms2, p_vms2)\n",
    "print(\"VMS1 P-value:\", vms2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57fc2c24-fb09-48a7-8e12-840a016513fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "LI normal: 715.6450615917975 +/- 414.505\n",
      "LI pathol: 675.0286693379126 +/- 385.4087\n"
     ]
    }
   ],
   "source": [
    "# compute li over full signals\n",
    "\n",
    "def compute_fft_mag_positive_f(data, fftpoints):\n",
    "    fft = np.fft.fft(data, n=fftpoints)\n",
    "    mag = np.abs(fft) / (fftpoints/2)\n",
    "    return mag\n",
    "\n",
    "def compute_loading_intensity(s, fft_points, fs, high_cut_off):\n",
    "    LI = 0\n",
    "    fc = high_cut_off\n",
    "    kc = int((fft_points/fs)* fc) + 1\n",
    "\n",
    "    magnitudes = compute_fft_mag_positive_f(s, fft_points)\n",
    "\n",
    "    f = []\n",
    "    for i in range(0, int(fft_points/2)+1):\n",
    "        f.append((fs*i)/fft_points)\n",
    "\n",
    "    for k in range(0, kc):\n",
    "        LI = LI + (magnitudes[k] * f[k])\n",
    "\n",
    "    return LI\n",
    "\n",
    "n_li = []\n",
    "n_li_ext_flex = []\n",
    "p_li = []\n",
    "p_li_ext_flex = []\n",
    "\n",
    "f_cut_off = 300 # as per the FD\n",
    "\n",
    "for i, n in enumerate(n_res):\n",
    "    li = compute_loading_intensity(n, len(n), fs, 1000) # high cutoff is nyquist\n",
    "    n_li.append(li)\n",
    "    n_li_ext = compute_loading_intensity(n_ext_flex[i][0], len(n_ext_flex[i][0]), fs, f_cut_off)\n",
    "    n_li_flx = compute_loading_intensity(n_ext_flex[i][1], len(n_ext_flex[i][1]), fs, f_cut_off)\n",
    "    n_li_ext_flex.append([n_li_ext, n_li_flx])\n",
    "\n",
    "    if(i < len(p_res)):\n",
    "        li = compute_loading_intensity(p_res[i], len(p_res[i]), fs, 1000) # high cutoff is nyquist\n",
    "        p_li.append(li)\n",
    "        p_li_ext = compute_loading_intensity(p_ext_flex[i][0], len(p_ext_flex[i][0]), fs, f_cut_off)\n",
    "        p_li_flx = compute_loading_intensity(p_ext_flex[i][1], len(p_ext_flex[i][1]), fs, f_cut_off)\n",
    "        p_li_ext_flex.append([p_li_ext, p_li_flx])\n",
    "\n",
    "print(len(n_li_ext_flex), len(p_li_ext_flex))\n",
    "\n",
    "print(f\"LI normal: {float(np.mean(n_li))} +/- {round(np.std(n_li),4)}\")\n",
    "print(f\"LI pathol: {np.mean(p_li)} +/- {round(np.std(p_li),4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "706332b1-43c9-402a-bbb9-1d63555bc96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LI P-value: 0.006544978798828279\n",
      "LI1 P-value: 0.7199508759471025\n",
      "LI2 P-value: 0.7952728601980096\n"
     ]
    }
   ],
   "source": [
    "# test p values for fd\n",
    "# check p values agains the paper - IDENTICAL\n",
    "li_t, li_p_value = stats.ttest_ind(n_li, p_li)\n",
    "print(\"LI P-value:\", fd_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_li1 = []\n",
    "p_li1 = []\n",
    "for r in n_li_ext_flex:\n",
    "    n_li1.append(r[0])\n",
    "for r in p_li_ext_flex:\n",
    "    p_li1.append(r[0])\n",
    "\n",
    "li1_t, li1_p_value = stats.ttest_ind(n_li1, p_li1)\n",
    "print(\"LI1 P-value:\", li1_p_value)\n",
    "\n",
    "n_li2 = []\n",
    "p_li2 = []\n",
    "for r in n_li_ext_flex:\n",
    "    n_li2.append(r[1])\n",
    "for r in p_li_ext_flex:\n",
    "    p_li2.append(r[1])\n",
    "\n",
    "li2_t, li2_p_value = stats.ttest_ind(n_li2, p_li2)\n",
    "print(\"LI2 P-value:\", li2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "706b5ee7-4583-43b1-856d-447ae4196493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "   STATE        FD    FD_EXT    FD_FLX       VMS   VMS_EXT   VMS_FLX  \\\n",
      "0      1  1.466570  1.775843  1.820782  0.025042  0.019168  0.029947   \n",
      "1      1  1.766607  1.627739  1.922575  0.004414  0.003966  0.003024   \n",
      "2      1  1.744344  1.869978  2.031547  0.003247  0.001370  0.004936   \n",
      "3      1  2.287178  2.038849  2.328853  0.000181  0.000233  0.000093   \n",
      "4      1  1.343740  1.526733  1.595508  0.010186  0.006659  0.003177   \n",
      "\n",
      "           LI      LI_EXT      LI_FLX  \n",
      "0  889.089284  159.510675  184.021034  \n",
      "1  631.959945  117.458492  114.770158  \n",
      "2  404.492380   50.910125   95.774558  \n",
      "3  261.686751  141.155890   23.514829  \n",
      "4  268.935033   80.879692   60.233316  \n"
     ]
    }
   ],
   "source": [
    "# turn the computed features into a dataframe\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# state\n",
    "n_state = np.ones(len(n_res),dtype=int)\n",
    "p_state = np.zeros(len(p_res), dtype=int)\n",
    "state = np.concatenate((n_state, p_state))\n",
    "\n",
    "# FD\n",
    "fd = np.concatenate((n_fd, p_fd))\n",
    "n_fd_ext_flx = np.array(n_ext_flex_fd)\n",
    "p_fd_ext_flx = np.array(p_ext_flex_fd)\n",
    "n_fd_ext = n_fd_ext_flx[:, 0]\n",
    "n_fd_flx = n_fd_ext_flx[:, 1]\n",
    "p_fd_ext = p_fd_ext_flx[:, 0]\n",
    "p_fd_flx = p_fd_ext_flx[:, 1]\n",
    "\n",
    "fd_ext = np.concatenate((n_fd_ext, p_fd_ext))\n",
    "fd_flx = np.concatenate((n_fd_flx, p_fd_flx))\n",
    "\n",
    "\n",
    "# VMS\n",
    "#n_mean_sqr = [] n_mean_sqr_ext_flex = [] p_mean_sqr = [] p_mean_sqr_ext_flex = []\n",
    "vms = np.concatenate((n_mean_sqr, p_mean_sqr))\n",
    "n_vms1 = np.array(n_mean_sqr_ext_flex)\n",
    "p_vms1 = np.array(p_mean_sqr_ext_flex)\n",
    "n_vms_ext = n_vms1[:, 0]\n",
    "n_vms_flx = n_vms1[:, 1]\n",
    "p_vms_ext = p_vms1[:, 0]\n",
    "p_vms_flx = p_vms1[:, 1]\n",
    "\n",
    "vms_ext = np.concatenate((n_vms_ext, p_vms_ext))\n",
    "vms_flx = np.concatenate((n_vms_flx, p_vms_flx))\n",
    "\n",
    "# LI\n",
    "#n_li = [] n_li_ext_flex = [] p_li = [] p_li_ext_flex = []\n",
    "\n",
    "li = np.concatenate((n_li, p_li))\n",
    "n_li1 = np.array(n_li_ext_flex)\n",
    "p_li1 = np.array(p_li_ext_flex)\n",
    "print(len(n_li1))\n",
    "n_li_ext = n_li1[:, 0]\n",
    "n_li_flx = n_li1[:, 1]\n",
    "p_li_ext = p_li1[:, 0]\n",
    "p_li_flx = p_li1[:, 1]\n",
    "\n",
    "li_ext = np.concatenate((n_li_ext, p_li_ext))\n",
    "li_flx = np.concatenate((n_li_flx, p_li_flx))\n",
    "\n",
    "df[\"STATE\"] = state\n",
    "df['FD'] = fd\n",
    "df['FD_EXT'] = fd_ext\n",
    "df['FD_FLX'] = fd_flx\n",
    "df['VMS'] = vms\n",
    "df['VMS_EXT'] = vms_ext\n",
    "df['VMS_FLX'] = vms_flx\n",
    "df['LI'] = li\n",
    "df['LI_EXT'] = li_ext\n",
    "df['LI_FLX'] = li_flx\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3e91ecaf-7eab-45b2-92f8-1ddaa804fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to csv in features directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3eaec02d-f7dc-4c55-9605-d9d2c05c00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'features'\n",
    "file_name = 'vag_features.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to avoid writing row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0799d-a625-429e-9bfd-4f2c3261540f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdf8f5-34c5-4267-a056-3b8c1bccfcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa2d56-f199-4008-a9f6-033605361d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83567172-4760-4c58-af47-0e7af78183f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 14:37:18.918367: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-07 14:37:18.918715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-07 14:37:18.920587: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-07 14:37:18.926226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-07 14:37:18.935567: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-07 14:37:18.938249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-07 14:37:18.945060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-07 14:37:19.355057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9596ea32-83d4-4e44-8f61-49c160b09396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_df(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "# should try filtered set also in case its better (but I dont know if the data was filtered prior or not)\n",
    "h_data_path = \"healthy.csv\"\n",
    "p_data_path = \"pathology.csv\"\n",
    "\n",
    "h_df = read_csv_to_df(h_data_path)\n",
    "p_df = read_csv_to_df(p_data_path)\n",
    "\n",
    "h_data = []\n",
    "p_data = []\n",
    "\n",
    "for spectrogram_id, group in h_df.groupby('spectrogram_id'):\n",
    "    # Extract frequency, time, and power values\n",
    "    power = []\n",
    "    for f, g in group.groupby(\"frequency\"):\n",
    "        p = g['power']\n",
    "        p_num = p.to_numpy()\n",
    "        power.append(p_num)\n",
    "    p_ = np.array(power)\n",
    "    p_shaped = p_.reshape(p_.shape[0], p_.shape[1], 1)  # Shape will be (129, 41, 1)\n",
    "    h_data.append(p_shaped)\n",
    "\n",
    "for spectrogram_id, group in p_df.groupby('spectrogram_id'):\n",
    "    # Extract frequency, time, and power values\n",
    "    power = []\n",
    "    for f, g in group.groupby(\"frequency\"):\n",
    "        p = g['power']\n",
    "        p_num = p.to_numpy()\n",
    "        power.append(p_num)\n",
    "    p_ = np.array(power)\n",
    "    p_shaped = p_.reshape(p_.shape[0], p_.shape[1], 1)  # Shape will be (129, 41, 1)\n",
    "    p_data.append(p_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e3ed45-d3d8-4dfa-87cd-abbb28b91bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_class_1: (51, 129, 41, 1)\n",
      "Shape of X_class_0: (38, 129, 41, 1)\n",
      "Shape of X: (89, 129, 41, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stack the arrays for class 1 and class 0\n",
    "X_class_1 = np.stack(h_data)  # Shape will be (n_samples_1, 129, 41, 1)\n",
    "X_class_0 = np.stack(p_data)  # Shape will be (n_samples_0, 129, 41, 1)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Shape of X_class_1:\", X_class_1.shape)  # Should show (n_samples_1, 129, 41, 1)\n",
    "print(\"Shape of X_class_0:\", X_class_0.shape)  # Should show (n_samples_0, 129, 41, 1)\n",
    "\n",
    "# Concatenate the stacked arrays\n",
    "X = np.concatenate((X_class_0, X_class_1), axis=0)  # Shape will be (total_samples, 129, 41, 1)\n",
    "print(\"Shape of X:\", X.shape) \n",
    "\n",
    "y_class_0 = np.zeros(X_class_0.shape[0])  # Labels for class 0\n",
    "y_class_1 = np.ones(X_class_1.shape[0])   # Labels for class 1\n",
    "y = np.concatenate((y_class_0, y_class_1))  # Combine labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95ba62e-6a14-4c69-bb26-4b20a3f4d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (89, 129, 41, 1)\n",
      "Shape of y: (89,)\n",
      "Type of X: <class 'numpy.ndarray'>\n",
      "Type of y: <class 'numpy.ndarray'>\n",
      "y dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset - this is done by the .fit method potentially?\n",
    "indices = np.arange(X.shape[0])  # Create an array of indices\n",
    "np.random.shuffle(indices)  # Shuffle indices\n",
    "X = X[indices]  # Shuffle the data\n",
    "y = y[indices]  # Shuffle the labels\n",
    "\n",
    "y = np.array(y, dtype=np.int32)  # Convert labels to int32\n",
    "X = np.array(X)  # it is already an np.array but making absolutely sure\n",
    "\n",
    "# verify shapes of data and types\n",
    "print(\"Shape of X:\", X.shape)  # Should be (total_samples, 129, 41, 1)\n",
    "print(\"Shape of y:\", y.shape)  # Should be (total_samples,)\n",
    "print(\"Type of X:\", type(X))  # Should be <class 'numpy.ndarray'>\n",
    "print(\"Type of y:\", type(y))  # Should be <class 'numpy.ndarray'>\n",
    "print(\"y dtype:\", y.dtype)  # Should show int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69e164-ae35-40b5-a5e0-226a2eebcb93",
   "metadata": {},
   "source": [
    "#### Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7fef27-9819-4352-8eb0-c584e352d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n",
      "<Sequential name=sequential_2, built=False>\n"
     ]
    }
   ],
   "source": [
    "# try sigmoid and softmax\n",
    "\n",
    "#### last results (restart kernal first) ##################\n",
    "# validation data of 0.1, batch_size 32\n",
    "# 107ms/step - accuracy: 0.9607 - loss: 0.0576  \n",
    "# Loss: 0.11523419618606567, Accuracy: 0.9213483333587646\n",
    "###########################################################\n",
    "\n",
    "#### last results (restart kernal first) ##################\n",
    "# validation data of 0.3, batch_size 32\n",
    "# 105ms/step - accuracy: 0.5795 - loss: 0.6805\n",
    "# Loss: 0.6825977563858032, Accuracy: 0.5730336904525757\n",
    "###########################################################\n",
    "\n",
    "def generate_model(activation):\n",
    "    a = (0,\"\")\n",
    "    if(activation == \"softmax\"):\n",
    "        a = (2, activation)\n",
    "    elif(activation == \"sigmoid\"):\n",
    "        a=(1, activation)\n",
    "    print(a[1])\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', ), # no input_shape=(129,41,1)\n",
    "        MaxPooling2D(pool_size=2, strides=1),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', ), # no input_shape=(129,41,1)\n",
    "        MaxPooling2D(pool_size=2, strides=1),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(a[0], activation=a[1])\n",
    "    \n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "activation = \"softmax\"\n",
    "model = generate_model(activation)\n",
    "print(model)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c1110-beec-4a89-afb6-77f28a46a9f0",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3c38b-60fe-467c-949c-a9e0185b49a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6153 - loss: 502.5535 - val_accuracy: 0.2778 - val_loss: 233.5586\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.4957 - loss: 152.5383 - val_accuracy: 0.7222 - val_loss: 41.4104\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5574 - loss: 30.8514 - val_accuracy: 0.2778 - val_loss: 24.1027\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.4785 - loss: 15.6320 - val_accuracy: 0.7222 - val_loss: 1.1886\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5254 - loss: 1.6714 - val_accuracy: 0.7222 - val_loss: 0.6346\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5364 - loss: 0.6915 - val_accuracy: 0.7222 - val_loss: 0.7536\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.4441 - loss: 1.1418 - val_accuracy: 0.6667 - val_loss: 0.6925\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5567 - loss: 0.6929 - val_accuracy: 0.7222 - val_loss: 0.6917\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5622 - loss: 0.6925 - val_accuracy: 0.2778 - val_loss: 0.7311\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.4957 - loss: 0.6823 - val_accuracy: 0.7222 - val_loss: 0.6908\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5254 - loss: 0.6925 - val_accuracy: 0.7222 - val_loss: 0.6903\n",
      "Epoch 12/50\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.4062 - loss: 0.6944"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "if(activation == \"softmax\"):\n",
    "    y = to_categorical(y, num_classes=2)  # Convert to one-hot encoding\n",
    "\n",
    "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88ce7a-210d-47ed-adbf-d125d82bcce0",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3de0b37-55a5-4f59-9860-e495c7f099bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5756 - loss: 0.6818\n",
      "Loss: 0.6824779510498047, Accuracy: 0.5730336904525757\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b8363-0a8d-4000-8e4f-06a0e7eb0c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

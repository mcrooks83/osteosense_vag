{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54364be6-a8a7-42e6-9b17-55cf393070cf",
   "metadata": {},
   "source": [
    "# Tuning Test\n",
    "#### https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17715657-613d-4d78-b850-c1a09049331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680916f4-da7d-40fb-a608-0b1a03c4a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_df(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "f_range = (10,950)\n",
    "\n",
    "h_data_path = f\"s_data/healthy_f_{f_range[0]}_{f_range[1]}.csv\"\n",
    "p_data_path = f\"s_data/pathology_f_{f_range[0]}_{f_range[1]}.csv\"\n",
    "\n",
    "h_df = read_csv_to_df(h_data_path)\n",
    "p_df = read_csv_to_df(p_data_path)\n",
    "\n",
    "h_data = []\n",
    "p_data = []\n",
    "\n",
    "for spectrogram_id, group in h_df.groupby('spectrogram_id'):\n",
    "    # Extract frequency, time, and power values\n",
    "    power = []\n",
    "    for f, g in group.groupby(\"frequency\"):\n",
    "        p = g['power']\n",
    "        p_num = p.to_numpy()\n",
    "        power.append(p_num)\n",
    "    p_ = np.array(power)\n",
    "    p_shaped = p_.reshape(p_.shape[0], p_.shape[1], 1)  # Shape will be (129, 41, 1)\n",
    "    h_data.append(p_shaped)\n",
    "\n",
    "for spectrogram_id, group in p_df.groupby('spectrogram_id'):\n",
    "    # Extract frequency, time, and power values\n",
    "    power = []\n",
    "    for f, g in group.groupby(\"frequency\"):\n",
    "        p = g['power']\n",
    "        p_num = p.to_numpy()\n",
    "        power.append(p_num)\n",
    "    p_ = np.array(power)\n",
    "    p_shaped = p_.reshape(p_.shape[0], p_.shape[1], 1)  # Shape will be (129, 41, 1)\n",
    "    p_data.append(p_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c2aeda-4eaa-4d08-9509-e00b77300596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_class_1: (51, 257, 33, 1)\n",
      "Shape of X_class_0: (38, 257, 33, 1)\n",
      "Shape of X: (89, 257, 33, 1)\n",
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "# Stack the arrays for class 1 and class 0\n",
    "X_class_1 = np.stack(h_data)  # Shape will be (n_samples_1, 129, 41, 1)\n",
    "X_class_0 = np.stack(p_data)  # Shape will be (n_samples_0, 129, 41, 1)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Shape of X_class_1:\", X_class_1.shape)  # Should show (n_samples_1, 129, 41, 1)\n",
    "print(\"Shape of X_class_0:\", X_class_0.shape)  # Should show (n_samples_0, 129, 41, 1)\n",
    "\n",
    "# Concatenate the stacked arrays\n",
    "X = np.concatenate((X_class_0, X_class_1), axis=0)  # Shape will be (total_samples, 129, 41, 1)\n",
    "print(\"Shape of X:\", X.shape) \n",
    "\n",
    "y_class_0 = np.zeros(X_class_0.shape[0])  # Labels for class 0\n",
    "y_class_1 = np.ones(X_class_1.shape[0])   # Labels for class 1\n",
    "y = np.concatenate((y_class_0, y_class_1))  # Combine labels\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ebc1d5-a230-4fa8-af94-b827a6aa54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=True,  random_state=42)\n",
    "y_train = np.array(y_train, dtype=np.int32)  # Convert labels to int32\n",
    "y_test = np.array(y_test, dtype=np.int32)  # Convert labels to int32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8ba5a38-6dbb-4497-9866-3be6df39ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 448 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    " \n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', ))\n",
    "\n",
    "    \n",
    "  model.add(keras.layers.Flatten())\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14785271-69f9-4a45-a617-04f3b806f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 742ms/step - accuracy: 0.5095 - loss: 0.7682 - val_accuracy: 0.6667 - val_loss: 31.3313\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step - accuracy: 0.8821 - loss: 0.2355 - val_accuracy: 0.2222 - val_loss: 36.3561\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 0.8821 - loss: 1.2867 - val_accuracy: 0.6667 - val_loss: 60.9134\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step - accuracy: 0.9705 - loss: 0.0425 - val_accuracy: 0.6667 - val_loss: 80.2952\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step - accuracy: 0.9705 - loss: 0.0240 - val_accuracy: 0.6667 - val_loss: 92.7095\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.6667 - val_loss: 100.6059\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.6667 - val_loss: 106.0801\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.6667 - val_loss: 110.1750\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6667 - val_loss: 113.3431\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6667 - val_loss: 115.8316\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 6.1994e-04 - val_accuracy: 0.6667 - val_loss: 117.8000\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step - accuracy: 1.0000 - loss: 3.4192e-04 - val_accuracy: 0.6667 - val_loss: 119.3695\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step - accuracy: 1.0000 - loss: 1.2518e-04 - val_accuracy: 0.6667 - val_loss: 120.5923\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step - accuracy: 1.0000 - loss: 1.0178e-04 - val_accuracy: 0.6667 - val_loss: 121.5240\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step - accuracy: 1.0000 - loss: 5.1226e-05 - val_accuracy: 0.6667 - val_loss: 122.2683\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 2.7886e-05 - val_accuracy: 0.6667 - val_loss: 122.8658\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685ms/step - accuracy: 1.0000 - loss: 1.6563e-05 - val_accuracy: 0.6667 - val_loss: 123.3472\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step - accuracy: 1.0000 - loss: 1.0761e-05 - val_accuracy: 0.6667 - val_loss: 123.7367\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 7.2884e-06 - val_accuracy: 0.6667 - val_loss: 124.0554\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 5.8655e-06 - val_accuracy: 0.6667 - val_loss: 124.3174\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 4.8681e-06 - val_accuracy: 0.6667 - val_loss: 124.5318\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step - accuracy: 1.0000 - loss: 4.2815e-06 - val_accuracy: 0.6667 - val_loss: 124.7075\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step - accuracy: 1.0000 - loss: 3.9338e-06 - val_accuracy: 0.6667 - val_loss: 124.8518\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 3.7301e-06 - val_accuracy: 0.6667 - val_loss: 124.9706\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 3.6282e-06 - val_accuracy: 0.6667 - val_loss: 125.0686\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 3.1568e-06 - val_accuracy: 0.6667 - val_loss: 125.1481\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 3.5474e-06 - val_accuracy: 0.6667 - val_loss: 125.2123\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 3.5404e-06 - val_accuracy: 0.6667 - val_loss: 125.2659\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step - accuracy: 1.0000 - loss: 2.3771e-06 - val_accuracy: 0.6667 - val_loss: 125.3156\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 2.6170e-06 - val_accuracy: 0.6667 - val_loss: 125.3689\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step - accuracy: 1.0000 - loss: 3.3709e-06 - val_accuracy: 0.6667 - val_loss: 125.4202\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 3.3156e-06 - val_accuracy: 0.6667 - val_loss: 125.4630\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 1.0000 - loss: 3.2208e-06 - val_accuracy: 0.6667 - val_loss: 125.4991\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step - accuracy: 1.0000 - loss: 2.3408e-06 - val_accuracy: 0.6667 - val_loss: 125.5352\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step - accuracy: 1.0000 - loss: 3.0487e-06 - val_accuracy: 0.6667 - val_loss: 125.5717\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 2.9539e-06 - val_accuracy: 0.6667 - val_loss: 125.6025\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 2.8731e-06 - val_accuracy: 0.6667 - val_loss: 125.6283\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step - accuracy: 1.0000 - loss: 2.8064e-06 - val_accuracy: 0.6667 - val_loss: 125.6501\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step - accuracy: 1.0000 - loss: 2.7537e-06 - val_accuracy: 0.6667 - val_loss: 125.6686\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step - accuracy: 1.0000 - loss: 2.7080e-06 - val_accuracy: 0.6667 - val_loss: 125.6844\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 2.6659e-06 - val_accuracy: 0.6667 - val_loss: 125.6978\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 2.5709e-06 - val_accuracy: 0.6667 - val_loss: 125.7089\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step - accuracy: 1.0000 - loss: 2.5913e-06 - val_accuracy: 0.6667 - val_loss: 125.7179\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 1.0000 - loss: 2.5851e-06 - val_accuracy: 0.6667 - val_loss: 125.7258\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 2.2695e-06 - val_accuracy: 0.6667 - val_loss: 125.7308\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 1.0000 - loss: 2.5303e-06 - val_accuracy: 0.6667 - val_loss: 125.7332\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 1.0000 - loss: 2.2452e-06 - val_accuracy: 0.6667 - val_loss: 125.7339\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step - accuracy: 1.0000 - loss: 2.4894e-06 - val_accuracy: 0.6667 - val_loss: 125.7329\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step - accuracy: 1.0000 - loss: 2.4211e-06 - val_accuracy: 0.6667 - val_loss: 125.7321\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step - accuracy: 1.0000 - loss: 2.4727e-06 - val_accuracy: 0.6667 - val_loss: 125.7315\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcd7a90c-270b-425d-a8c7-5d8e7cb2879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 764ms/step - accuracy: 0.3432 - loss: 1.6173 - val_accuracy: 0.6667 - val_loss: 15.3871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x760e655f46d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05ea8dcd-4efd-4f04-a989-7de83f56b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4674 - loss: 22.2829\n",
      "[test loss, test accuracy]: [20.656692504882812, 0.46666666865348816]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac63d2a-07ab-4ebf-9fe0-4d93fd2d5d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56bb5b-1e7a-4e77-8f2e-330db827dfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

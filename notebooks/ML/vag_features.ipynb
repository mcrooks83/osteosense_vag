{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681ba41f-51e8-4cdd-a3e8-9ecb83ac5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import statistics as stats\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from scipy.signal import medfilt, butter, filtfilt, lfilter, find_peaks, find_peaks_cwt,resample, detrend\n",
    "from scipy.signal import welch, spectrogram, get_window\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e208e-5399-49bf-bc13-43b105fceb0b",
   "metadata": {},
   "source": [
    "Goal is to create a feature set consisting of\n",
    "\n",
    "1. Fractal dimension\n",
    "2. VMS\n",
    "3. LI\n",
    "\n",
    "OUTPUT: A csv file of the features with 0 for normal and 1 for pathological\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3aad5e-e7ef-4dd8-83d7-20d85e084ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mike/Desktop/apps/research/VAG/notebooks/ML\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#os.chdir(cwd+'/ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26aa3bd3-e651-4b59-b274-7ddbde641b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " healthy vag signals 51\n",
      " pathology vag signals 38\n"
     ]
    }
   ],
   "source": [
    "healthy_dir = \"../../data/open_vag/normal/\"\n",
    "pathology_dir = \"../../data/open_vag/pathology/\"\n",
    "#healthy_base = \"novag\"\n",
    "#pathology_base  = \"abvag\"\n",
    "\n",
    "healthy_subs = [] # 51\n",
    "pathology_subs = [] # 38\n",
    "\n",
    "exclude = {\".ipynb_checkpoints\"}\n",
    "\n",
    "healthy_files = [f for f in os.listdir(healthy_dir) if '.ipynb_checkpoints' not in f]\n",
    "print(f\" healthy vag signals {len(healthy_files)}\")\n",
    "pathology_files = [f for f in os.listdir(pathology_dir) if '.ipynb_checkpoints' not in f]\n",
    "print(f\" pathology vag signals {len(pathology_files)}\")\n",
    "\n",
    "max_size_files = max(len(healthy_files), len(pathology_files))\n",
    "\n",
    "for i in range(0, max_size_files):\n",
    "    if(i < len(healthy_files)):\n",
    "        # read in a healthy_file\n",
    "        file_path = os.path.join(healthy_dir, healthy_files[i])\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read all the floating-point numbers into a list\n",
    "            vags = [float(x) for x in file.read().split()]\n",
    "            healthy_subs.append(vags)\n",
    "    if(i < len(pathology_files)):\n",
    "        file_path = os.path.join(pathology_dir, pathology_files[i])\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read all the floating-point numbers into a list\n",
    "            vags = [float(x) for x in file.read().split()]\n",
    "            pathology_subs.append(vags)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8860193-e577-4b32-955b-4b2bd01568c6",
   "metadata": {},
   "source": [
    "First step is to normalise, filter, resample and split the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94bd4c2-f8d6-41be-b77d-568614108e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 4000 4000\n"
     ]
    }
   ],
   "source": [
    "def amplitude_normal(signal):\n",
    "    sig = np.array(signal)\n",
    "    data_min = min(sig)\n",
    "    data_max = max(sig)\n",
    "    normal = (sig - data_min) / (data_max - data_min)\n",
    "    return normal.tolist()\n",
    "\n",
    "# not used anymore\n",
    "def resample_signal(signal, points, fs):\n",
    "    t = np.linspace(0, fs, num=len(signal))\n",
    "    x_new = np.linspace(t.min(), t.max(), points)\n",
    "    interpolator = interp1d(t, signal, kind='linear')\n",
    "    y_new = interpolator(x_new)\n",
    "    return y_new\n",
    "\n",
    "def split_signal(signal):\n",
    "    middle = len(signal) // 2\n",
    "    # Split the array into two halves\n",
    "    first_half = signal[:middle]\n",
    "    second_half = signal[middle:]\n",
    "    \n",
    "    return [first_half, second_half]\n",
    "\n",
    "def build_filter(frequency, sample_rate, filter_type, filter_order):\n",
    "    #nyq = 0.5 * sample_rate\n",
    "    if filter_type == \"bandpass\":\n",
    "        #nyq_cutoff = (frequency[0] / nyq, frequency[1] / nyq)\n",
    "        b, a = butter(filter_order, (frequency[0], frequency[1]), btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "    elif filter_type == \"low\":\n",
    "        #nyq_cutoff = frequency[1] / nyq\n",
    "        b, a = butter(filter_order, frequency[1] / ny, btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "    elif filter_type == \"high\":\n",
    "        #nyq_cutoff = frequency[0] / nyq\n",
    "        b, a = butter(filter_order, frequency[0], btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "\n",
    "    return b, a\n",
    "\n",
    "def filter_signal(b, a, signal, filter):\n",
    "    if(filter==\"lfilter\"):\n",
    "        return lfilter(b, a, signal)\n",
    "    elif(filter==\"filtfilt\"):\n",
    "        return filtfilt(b, a, signal)\n",
    "    elif(filter==\"sos\"):\n",
    "        return sosfiltfilt(sos, signal)\n",
    "\n",
    "r_l = 8000\n",
    "fs = 2000 # 2khz sampling rate\n",
    "low_cut_off = 100 # removes muscle artifacts and baseline wander\n",
    "high_cut_off = 750\n",
    "filter_order = 5   # 9th order has been used in literature?\n",
    "filter_type =  \"bandpass\"  #\"bandpass\", high, low\n",
    "b,a = build_filter((low_cut_off, high_cut_off), fs, filter_type, filter_order)\n",
    "\n",
    "n_res = [] # resampled normal vag signal\n",
    "n_ext_flex = [] # resampled split vag signal\n",
    "p_res = [] # resampled normal pathological signal\n",
    "p_ext_flex = [] # resampled split pathological signal\n",
    "\n",
    "for d_set in healthy_subs:\n",
    "    n = amplitude_normal(d_set)\n",
    "    #n_resampled = resample_signal(n, r_l, fs)\n",
    "    y_new = resample(n, r_l)\n",
    "    y_new_f = filter_signal(b,a,y_new,\"filtfilt\")\n",
    "    n_res.append(y_new)\n",
    "\n",
    "    # split into extension / flexion\n",
    "    ext_flex = split_signal(y_new_f)  # ext is 0 and flex is 1\n",
    "    n_ext_flex.append(ext_flex)\n",
    "\n",
    "for d_set in pathology_subs:\n",
    "    p = amplitude_normal(d_set)\n",
    "    #p_resampled = resample_signal(p, r_l, fs)\n",
    "    y_new = resample(p, r_l)\n",
    "    y_new_f = filter_signal(b,a,y_new,\"filtfilt\")\n",
    "    p_res.append(y_new_f)\n",
    "\n",
    "    # split into extension / flexion\n",
    "    ext_flex = split_signal(y_new_f)  # ext is 0 and flex is 1\n",
    "    p_ext_flex.append(ext_flex)\n",
    "\n",
    "print(len(n_res[0]), len(n_ext_flex[0][0]), len(n_ext_flex[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18db26e2-56d0-4d0c-b433-daca79e51cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "avg fd normal: 1.8476369324826152 +/- 0.2277\n",
      "avg fd pathol: -2.4423922863813936 +/- 0.1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7700/456299692.py:32: RuntimeWarning: divide by zero encountered in log10\n",
      "  s_log_f = np.log10(s_x)\n",
      "/tmp/ipykernel_7700/456299692.py:32: RuntimeWarning: invalid value encountered in log10\n",
      "  s_log_f = np.log10(s_x)\n"
     ]
    }
   ],
   "source": [
    "# compute the fractal dimension of each signal \n",
    "\n",
    "def apply_hanning(d):\n",
    "    hanning_window = np.hanning(len(d))\n",
    "    windowed_signal = d * hanning_window\n",
    "    return windowed_signal\n",
    "\n",
    "# assumes len(data) is a fft multiple i.e 4096 or 8192\n",
    "def compute_fft_mag(data):\n",
    "    fftpoints = len(data) #int(math.pow(2, math.ceil(math.log2(len(data)))))\n",
    "    fft = np.fft.fft(data, n=fftpoints)\n",
    "    mag = np.abs(fft) #/ (fftpoints/2)\n",
    "    return mag\n",
    "\n",
    "# assumes a numpy arrray\n",
    "def compute_power_spectrum(fft_mag):\n",
    "    power = np.square(fft_mag)\n",
    "    return power\n",
    "    \n",
    "def compute_fd(slope):\n",
    "    fd = (5 - abs(slope)) / 2\n",
    "    return fd\n",
    "\n",
    "def vag_to_fd(s):\n",
    "    s_han = apply_hanning(s)\n",
    "    #compute fft and power spectrum\n",
    "    s_fft = compute_fft_mag(s_han)\n",
    "    s_pwr = compute_power_spectrum(s_fft)\n",
    "    # get the frequency axis\n",
    "    s_x = np.fft.fftfreq(len(s), d=1/fs)\n",
    "    # compute the log log\n",
    "    s_log_f = np.log10(s_x)\n",
    "    s_log_pwr = np.log10(s_pwr)\n",
    "\n",
    "    indices = np.where((s_x > 10) & (s_x < 300))[0]\n",
    "    x = s_log_f[indices]\n",
    "    y = s_log_pwr[indices]\n",
    "    m, b, r_value, p_value, std_err = linregress(x, y)\n",
    "    # we only care about the slope for fd\n",
    "    s_fd = compute_fd(m)\n",
    "    return s_fd\n",
    "\n",
    "# frequency range to compute fd (Hz)\n",
    "min_f = 100  \n",
    "max_f = 750\n",
    "\n",
    "n_fd = []\n",
    "n_ext_flex_fd = []\n",
    "p_fd = []\n",
    "p_ext_flex_fd = []\n",
    "\n",
    "# normal vag signals\n",
    "for i, n in enumerate(n_res):\n",
    "    fd = vag_to_fd(n)\n",
    "    n_fd.append(fd)\n",
    "\n",
    "    # compute fd for extension and flexion\n",
    "    fd_ext = vag_to_fd(n_ext_flex[i][0])\n",
    "    fd_flex = vag_to_fd(n_ext_flex[i][1])\n",
    "    n_ext_flex_fd.append([fd_ext, fd_flex])\n",
    "\n",
    "    # compute for pathological signal\n",
    "    if(i < len(p_res)):\n",
    "        fd = vag_to_fd(p_res[i])\n",
    "        p_fd.append(fd)\n",
    "\n",
    "        fd_ext = vag_to_fd(p_ext_flex[i][0])\n",
    "        fd_flex = vag_to_fd(p_ext_flex[i][1])\n",
    "        p_ext_flex_fd.append([fd_ext, fd_flex])\n",
    "\n",
    "print(len(n_fd), len(p_fd))\n",
    "\n",
    "print(f\"avg fd normal: {float(np.mean(n_fd))} +/- {round(np.std(n_fd),4)}\")\n",
    "print(f\"avg fd pathol: {np.mean(p_fd)} +/- {round(np.std(p_fd),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1c12d-4ee3-4340-b98c-8f8ac5ff8c82",
   "metadata": {},
   "source": [
    "statistically highly signiﬁcant (p < 0.01),\n",
    "statistically signiﬁcant (0.01 < p < 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf328a81-c2e0-448a-896b-f3ff09e03f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD P-value: 8.901377374682255e-89\n",
      "FD1 P-value: 0.6043349254950423\n",
      "FD2 P-value: 0.2988447806655629\n"
     ]
    }
   ],
   "source": [
    "# test p values for fd\n",
    "# check p values agains the paper - IDENTICAL\n",
    "fd_t, fd_p_value = stats.ttest_ind(n_fd, p_fd)\n",
    "print(\"FD P-value:\", fd_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_fd1 = []\n",
    "p_fd1 = []\n",
    "for r in n_ext_flex_fd:\n",
    "    n_fd1.append(r[0])\n",
    "for r in p_ext_flex_fd:\n",
    "    p_fd1.append(r[0])\n",
    "\n",
    "fd1_t, fd1_p_value = stats.ttest_ind(n_fd1, p_fd1)\n",
    "print(\"FD1 P-value:\", fd1_p_value)\n",
    "\n",
    "n_fd2 = []\n",
    "p_fd2 = []\n",
    "for r in n_ext_flex_fd:\n",
    "    n_fd2.append(r[1])\n",
    "for r in p_ext_flex_fd:\n",
    "    p_fd2.append(r[1])\n",
    "\n",
    "fd2_t, fd2_p_value = stats.ttest_ind(n_fd2, p_fd2)\n",
    "print(\"FD2 P-value:\", fd2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b663abfd-9cdf-4012-a190-3150b51d3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "VMS normal: 0.005747573490845162 +/- 0.0061\n",
      "VMS pathol: 1.332847933043984e-07 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# compute the VMS -> Mean Squared every 5ms \n",
    "# 2khz and 5ms = 10 samples per block\n",
    "\n",
    "# window in seconds - 0.005 is 5ms fs in Hz \n",
    "def compute_mean_squared_variance(signal, fs, window=0.005):\n",
    "    samples_per_group = int(window * fs)\n",
    "    num_groups = len(signal) // samples_per_group\n",
    "    \n",
    "    # Slice the array to only include full groups\n",
    "    trimmed_array = signal[:num_groups * samples_per_group]\n",
    "    \n",
    "    # Reshape the array into a 2D array where each row is a group of 10 samples\n",
    "    reshaped_array = trimmed_array.reshape(num_groups, samples_per_group)\n",
    "    #mean = np.mean(reshaped_array, axis=1)\n",
    "    mean_squared = [np.mean(row)**2 for row in reshaped_array]\n",
    "    variance = np.var(mean_squared)\n",
    "    \n",
    "    return variance, mean_squared\n",
    "    \n",
    "n_list = []\n",
    "p_list = []\n",
    "n_mean_sqr = []\n",
    "n_mean_sqr_ext_flex = []\n",
    "p_mean_sqr = []\n",
    "p_mean_sqr_ext_flex = []\n",
    "\n",
    "for i, n in enumerate(n_res):\n",
    "    var, n_m_sqr = compute_mean_squared_variance(n, fs)\n",
    "    n_mean_sqr.append(var)\n",
    "    n_list.append(n_m_sqr)\n",
    "    var_ext, n_sqr_ext = compute_mean_squared_variance(n_ext_flex[i][0], fs)\n",
    "    var_flex, n_sqr_flx = compute_mean_squared_variance(n_ext_flex[i][1], fs)\n",
    "    n_mean_sqr_ext_flex.append([var_ext, var_flex])\n",
    "\n",
    "    if(i < len(p_res)):\n",
    "        p_var, p_m_sqr = compute_mean_squared_variance(p_res[i], fs)\n",
    "        p_mean_sqr.append(p_var)\n",
    "        p_list.append(p_m_sqr)\n",
    "    \n",
    "        p_var_ext, p_sqr_ext = compute_mean_squared_variance(p_ext_flex[i][0], fs)\n",
    "        p_var_flex, p_sqr_flx = compute_mean_squared_variance(p_ext_flex[i][1], fs)\n",
    "        p_mean_sqr_ext_flex.append([p_var_ext, p_var_flex])\n",
    "\n",
    "\n",
    "print(len(n_mean_sqr), len(p_mean_sqr))\n",
    "\n",
    "print(f\"VMS normal: {float(np.mean(n_mean_sqr))} +/- {round(np.std(n_mean_sqr),4)}\")\n",
    "print(f\"VMS pathol: {np.mean(p_mean_sqr)} +/- {round(np.std(p_mean_sqr),4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827f70e7-16ef-4754-9983-3002db7a87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMS P-value: 1.5533644595748518e-07\n",
      "VMS1 P-value: 0.21970206938834727\n",
      "VMS1 P-value: 0.36684764048447094\n"
     ]
    }
   ],
   "source": [
    "# check p values agains the paper - IDENTICAL\n",
    "vms_t, vms_p_value = stats.ttest_ind(n_mean_sqr, p_mean_sqr)\n",
    "print(\"VMS P-value:\", vms_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_vms1 = []\n",
    "p_vms1 = []\n",
    "for r in n_mean_sqr_ext_flex:\n",
    "    n_vms1.append(r[0])\n",
    "for r in p_mean_sqr_ext_flex:\n",
    "    p_vms1.append(r[0])\n",
    "\n",
    "vms1_t, vms1_p_value = stats.ttest_ind(n_vms1, p_vms1)\n",
    "print(\"VMS1 P-value:\", vms1_p_value)\n",
    "\n",
    "#flextion\n",
    "n_vms2 = []\n",
    "p_vms2 = []\n",
    "for r in n_mean_sqr_ext_flex:\n",
    "    n_vms2.append(r[1])\n",
    "for r in p_mean_sqr_ext_flex:\n",
    "    p_vms2.append(r[1])\n",
    "    \n",
    "vms2_t, vms2_p_value = stats.ttest_ind(n_vms2, p_vms2)\n",
    "print(\"VMS1 P-value:\", vms2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fc2c24-fb09-48a7-8e12-840a016513fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n",
      "LI normal: 938.4904305107437 +/- 558.1397\n",
      "LI pathol: 549.8706828941058 +/- 305.3874\n"
     ]
    }
   ],
   "source": [
    "# compute li over full signals\n",
    "\n",
    "def compute_fft_mag_positive_f(data, fftpoints):\n",
    "    fft = np.fft.fft(data, n=fftpoints)\n",
    "    mag = np.abs(fft) / (fftpoints/2)\n",
    "    return mag\n",
    "\n",
    "def compute_loading_intensity(s, fft_points, fs, high_cut_off):\n",
    "    LI = 0\n",
    "    fc = high_cut_off\n",
    "    kc = int((fft_points/fs)* fc) + 1\n",
    "\n",
    "    magnitudes = compute_fft_mag_positive_f(s, fft_points)\n",
    "\n",
    "    f = []\n",
    "    for i in range(0, int(fft_points/2)+1):\n",
    "        f.append((fs*i)/fft_points)\n",
    "\n",
    "    for k in range(0, kc):\n",
    "        LI = LI + (magnitudes[k] * f[k])\n",
    "\n",
    "    return LI\n",
    "\n",
    "n_li = []\n",
    "n_li_ext_flex = []\n",
    "p_li = []\n",
    "p_li_ext_flex = []\n",
    "\n",
    "f_cut_off = 300 # as per the FD\n",
    "\n",
    "for i, n in enumerate(n_res):\n",
    "    li = compute_loading_intensity(n, len(n), fs, 1000) # high cutoff is nyquist\n",
    "    n_li.append(li)\n",
    "    n_li_ext = compute_loading_intensity(n_ext_flex[i][0], len(n_ext_flex[i][0]), fs, f_cut_off)\n",
    "    n_li_flx = compute_loading_intensity(n_ext_flex[i][1], len(n_ext_flex[i][1]), fs, f_cut_off)\n",
    "    n_li_ext_flex.append([n_li_ext, n_li_flx])\n",
    "\n",
    "    if(i < len(p_res)):\n",
    "        li = compute_loading_intensity(p_res[i], len(p_res[i]), fs, 1000) # high cutoff is nyquist\n",
    "        p_li.append(li)\n",
    "        p_li_ext = compute_loading_intensity(p_ext_flex[i][0], len(p_ext_flex[i][0]), fs, f_cut_off)\n",
    "        p_li_flx = compute_loading_intensity(p_ext_flex[i][1], len(p_ext_flex[i][1]), fs, f_cut_off)\n",
    "        p_li_ext_flex.append([p_li_ext, p_li_flx])\n",
    "\n",
    "print(len(n_li_ext_flex), len(p_li_ext_flex))\n",
    "\n",
    "print(f\"LI normal: {float(np.mean(n_li))} +/- {round(np.std(n_li),4)}\")\n",
    "print(f\"LI pathol: {np.mean(p_li)} +/- {round(np.std(p_li),4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706332b1-43c9-402a-bbb9-1d63555bc96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LI P-value: 8.901377374682255e-89\n",
      "LI1 P-value: 0.3635732686481704\n",
      "LI2 P-value: 0.49974575970771573\n"
     ]
    }
   ],
   "source": [
    "# test p values for fd\n",
    "# check p values agains the paper - IDENTICAL\n",
    "li_t, li_p_value = stats.ttest_ind(n_li, p_li)\n",
    "print(\"LI P-value:\", fd_p_value)\n",
    "\n",
    "#extenstion\n",
    "n_li1 = []\n",
    "p_li1 = []\n",
    "for r in n_li_ext_flex:\n",
    "    n_li1.append(r[0])\n",
    "for r in p_li_ext_flex:\n",
    "    p_li1.append(r[0])\n",
    "\n",
    "li1_t, li1_p_value = stats.ttest_ind(n_li1, p_li1)\n",
    "print(\"LI1 P-value:\", li1_p_value)\n",
    "\n",
    "n_li2 = []\n",
    "p_li2 = []\n",
    "for r in n_li_ext_flex:\n",
    "    n_li2.append(r[1])\n",
    "for r in p_li_ext_flex:\n",
    "    p_li2.append(r[1])\n",
    "\n",
    "li2_t, li2_p_value = stats.ttest_ind(n_li2, p_li2)\n",
    "print(\"LI2 P-value:\", li2_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706b5ee7-4583-43b1-856d-447ae4196493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "   STATE        FD    FD_EXT    FD_FLX       VMS       VMS_EXT       VMS_FLX  \\\n",
      "0      1  1.714624 -1.953987 -1.893786  0.003594  7.705657e-09  5.391020e-08   \n",
      "1      1  1.876535 -2.437410 -2.631023  0.017189  2.282283e-08  4.681395e-08   \n",
      "2      1  1.858951 -2.675034 -2.419703  0.010199  4.082311e-08  3.568691e-08   \n",
      "3      1  1.640282 -1.989119 -2.217110  0.003709  4.987345e-08  3.646279e-09   \n",
      "4      1  1.743807 -2.269572 -2.401506  0.024151  3.403807e-08  7.599448e-09   \n",
      "\n",
      "            LI      LI_EXT      LI_FLX  \n",
      "0   684.049676   74.933167  103.381055  \n",
      "1  1746.572715  154.270082  159.203130  \n",
      "2  1919.730051  197.739256  183.806528  \n",
      "3   559.070428   62.157193   73.515731  \n",
      "4  1238.495077  134.842340  131.481354  \n"
     ]
    }
   ],
   "source": [
    "# turn the computed features into a dataframe\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# state\n",
    "n_state = np.ones(len(n_res),dtype=int)\n",
    "p_state = np.zeros(len(p_res), dtype=int)\n",
    "state = np.concatenate((n_state, p_state))\n",
    "\n",
    "# FD\n",
    "fd = np.concatenate((n_fd, p_fd))\n",
    "n_fd_ext_flx = np.array(n_ext_flex_fd)\n",
    "p_fd_ext_flx = np.array(p_ext_flex_fd)\n",
    "n_fd_ext = n_fd_ext_flx[:, 0]\n",
    "n_fd_flx = n_fd_ext_flx[:, 1]\n",
    "p_fd_ext = p_fd_ext_flx[:, 0]\n",
    "p_fd_flx = p_fd_ext_flx[:, 1]\n",
    "\n",
    "fd_ext = np.concatenate((n_fd_ext, p_fd_ext))\n",
    "fd_flx = np.concatenate((n_fd_flx, p_fd_flx))\n",
    "\n",
    "\n",
    "# VMS\n",
    "#n_mean_sqr = [] n_mean_sqr_ext_flex = [] p_mean_sqr = [] p_mean_sqr_ext_flex = []\n",
    "vms = np.concatenate((n_mean_sqr, p_mean_sqr))\n",
    "n_vms1 = np.array(n_mean_sqr_ext_flex)\n",
    "p_vms1 = np.array(p_mean_sqr_ext_flex)\n",
    "n_vms_ext = n_vms1[:, 0]\n",
    "n_vms_flx = n_vms1[:, 1]\n",
    "p_vms_ext = p_vms1[:, 0]\n",
    "p_vms_flx = p_vms1[:, 1]\n",
    "\n",
    "vms_ext = np.concatenate((n_vms_ext, p_vms_ext))\n",
    "vms_flx = np.concatenate((n_vms_flx, p_vms_flx))\n",
    "\n",
    "# LI\n",
    "#n_li = [] n_li_ext_flex = [] p_li = [] p_li_ext_flex = []\n",
    "\n",
    "li = np.concatenate((n_li, p_li))\n",
    "n_li1 = np.array(n_li_ext_flex)\n",
    "p_li1 = np.array(p_li_ext_flex)\n",
    "print(len(n_li1))\n",
    "n_li_ext = n_li1[:, 0]\n",
    "n_li_flx = n_li1[:, 1]\n",
    "p_li_ext = p_li1[:, 0]\n",
    "p_li_flx = p_li1[:, 1]\n",
    "\n",
    "li_ext = np.concatenate((n_li_ext, p_li_ext))\n",
    "li_flx = np.concatenate((n_li_flx, p_li_flx))\n",
    "\n",
    "df[\"STATE\"] = state\n",
    "df['FD'] = fd\n",
    "df['FD_EXT'] = fd_ext\n",
    "df['FD_FLX'] = fd_flx\n",
    "df['VMS'] = vms\n",
    "df['VMS_EXT'] = vms_ext\n",
    "df['VMS_FLX'] = vms_flx\n",
    "df['LI'] = li\n",
    "df['LI_EXT'] = li_ext\n",
    "df['LI_FLX'] = li_flx\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e91ecaf-7eab-45b2-92f8-1ddaa804fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to csv in features directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eaec02d-f7dc-4c55-9605-d9d2c05c00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'features'\n",
    "file_name = 'vag_features.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to avoid writing row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0799d-a625-429e-9bfd-4f2c3261540f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdf8f5-34c5-4267-a056-3b8c1bccfcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa2d56-f199-4008-a9f6-033605361d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

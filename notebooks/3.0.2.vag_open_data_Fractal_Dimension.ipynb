{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a120f054-9047-4bbd-bdb4-d71f929463a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import statistics as stats\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from scipy.signal import medfilt, butter, filtfilt, lfilter, find_peaks, find_peaks_cwt,resample, detrend\n",
    "from scipy.signal import welch, spectrogram, get_window\n",
    "from scipy.stats import linregress\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6941260-faa3-43a0-a68c-f8c5cce03ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " healthy vag signals 51\n",
      " pathology vag signals 38\n",
      "51 38\n"
     ]
    }
   ],
   "source": [
    "normal_vag_subjects = [] # 51\n",
    "pathology_vag_subjects = [] # 38\n",
    "\n",
    "healthy_dir = \"../data/open_vag/normal/\"\n",
    "pathology_dir = \"../data/open_vag/pathology/\"\n",
    "#healthy_base = \"novag\"\n",
    "#pathology_base  = \"abvag\"\n",
    "\n",
    "\n",
    "exclude = {\".ipynb_checkpoints\"}\n",
    "\n",
    "healthy_files = [f for f in os.listdir(healthy_dir) if '.ipynb_checkpoints' not in f]\n",
    "print(f\" healthy vag signals {len(healthy_files)}\")\n",
    "pathology_files = [f for f in os.listdir(pathology_dir) if '.ipynb_checkpoints' not in f]\n",
    "print(f\" pathology vag signals {len(pathology_files)}\")\n",
    "\n",
    "max_size_files = max(len(healthy_files), len(pathology_files))\n",
    "\n",
    "for i in range(0, max_size_files):\n",
    "    if(i < len(healthy_files)):\n",
    "        # read in a healthy_file\n",
    "        file_path = os.path.join(healthy_dir, healthy_files[i])\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read all the floating-point numbers into a list\n",
    "            vags = [float(x) for x in file.read().split()]\n",
    "            normal_vag_subjects.append(vags)\n",
    "    if(i < len(pathology_files)):\n",
    "        file_path = os.path.join(pathology_dir, pathology_files[i])\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read all the floating-point numbers into a list\n",
    "            vags = [float(x) for x in file.read().split()]\n",
    "            pathology_vag_subjects.append(vags)  \n",
    "\n",
    "print(len(normal_vag_subjects), len(pathology_vag_subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9ff1fb-a040-4de1-9325-9803900f409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amplitude normalisation\n",
    "def amplitude_normal(signal):\n",
    "    sig = np.array(signal)\n",
    "    data_min = min(sig)\n",
    "    data_max = max(sig)\n",
    "    normal = (sig - data_min) / (data_max - data_min)\n",
    "    return normal.tolist()\n",
    "\n",
    "def resample_signal(signal, points):\n",
    "    s_res = resample(signal, points)\n",
    "    return s_res\n",
    "\n",
    "def build_filter(frequency, sample_rate, filter_type, filter_order):\n",
    "    #nyq = 0.5 * sample_rate\n",
    "    if filter_type == \"bandpass\":\n",
    "        #nyq_cutoff = (frequency[0] / nyq, frequency[1] / nyq)\n",
    "        b, a = butter(filter_order, (frequency[0], frequency[1]), btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "    elif filter_type == \"low\":\n",
    "        #nyq_cutoff = frequency[1] / nyq\n",
    "        b, a = butter(filter_order, frequency[1] / ny, btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "    elif filter_type == \"high\":\n",
    "        #nyq_cutoff = frequency[0] / nyq\n",
    "        b, a = butter(filter_order, frequency[0], btype=filter_type, analog=False, output='ba', fs=sample_rate)\n",
    "\n",
    "    return b, a\n",
    "\n",
    "def filter_signal(b, a, signal, filter):\n",
    "    if(filter==\"lfilter\"):\n",
    "        return lfilter(b, a, signal)\n",
    "    elif(filter==\"filtfilt\"):\n",
    "        return filtfilt(b, a, signal)\n",
    "    elif(filter==\"sos\"):\n",
    "        return sosfiltfilt(sos, signal)\n",
    "\n",
    "# variables\n",
    "n_l = 8192\n",
    "fs = 2000 # 2khz sampling rate\n",
    "low_cut_off = 10 # removes muscle artifacts and baseline wander\n",
    "high_cut_off = 950\n",
    "filter_order = 5   # 9th order has been used in literature?\n",
    "filter_type =  \"bandpass\"  #\"bandpass\", high, low\n",
    "b,a = build_filter((low_cut_off, high_cut_off), fs, filter_type, filter_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a383d7e-7ce6-4022-ba75-22ae47183c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 38\n"
     ]
    }
   ],
   "source": [
    "n_norm_res = []\n",
    "p_norm_res = []\n",
    "\n",
    "for d_set in normal_vag_subjects:\n",
    "    n = amplitude_normal(d_set)\n",
    "    y_new = resample(n, n_l)\n",
    "    y_new_f = filter_signal(b,a,y_new,\"filtfilt\")\n",
    "    n_norm_res.append(y_new_f)\n",
    "\n",
    "for d_set in pathology_vag_subjects:\n",
    "    p = amplitude_normal(d_set)\n",
    "    y_new = resample(p, n_l)\n",
    "    y_new_f = filter_signal(b,a,y_new,\"filtfilt\")\n",
    "    p_norm_res.append(y_new_f)\n",
    "\n",
    "print(len(n_norm_res), len(p_norm_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49e16bd-7e80-4bb8-aead-86eaaaa1b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(len(normal_vag_subjects),2, figsize=(20, 100))\n",
    "#for i, n in enumerate(n_norm_res):\n",
    "#    ax[i][0].plot(n)\n",
    "#for i, p in enumerate(p_norm_res):\n",
    "#ax[i][1].plot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b770bc9-e012-48f3-a8d0-32f4ee2b5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(len(n_norm),2, figsize=(20, 100))\n",
    "\n",
    "#for i, d in enumerate(n_norm_res):\n",
    "#    t_n = np.arange(1, len(d) + 1) / fs\n",
    "\n",
    "#    t_n_2 = np.arange(1, len(n_norm[i])+1) / fs\n",
    "#    ax[i][0].plot(t_n, d, color=\"m\")\n",
    "#    ax[i][1].plot(t_n_2, n_norm[i], color=\"c\")\n",
    "#    #ax[i][1].plot(t_n, n_hanning[i], color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b39a37-2040-41f1-92df-538691628261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def split_signal(signal):\n",
    "    middle = len(signal) // 2\n",
    "    # Split the array into two halves\n",
    "    first_half = signal[:middle]\n",
    "    second_half = signal[middle:]\n",
    "    \n",
    "    return [first_half, second_half]\n",
    "\n",
    "def apply_hanning(d):\n",
    "    hanning_window = np.hanning(len(d))\n",
    "    windowed_signal = d * hanning_window\n",
    "    return windowed_signal\n",
    "\n",
    "# assumes len(data) is a fft multiple i.e 4096 or 8192\n",
    "def compute_fft_mag(data):\n",
    "    fftpoints = len(data) #int(math.pow(2, math.ceil(math.log2(len(data)))))\n",
    "    fft = np.fft.fft(data, n=fftpoints)\n",
    "    mag = np.abs(fft) #/ (fftpoints/2)\n",
    "    return mag\n",
    "\n",
    "# assumes a numpy arrray\n",
    "def compute_power_spectrum(fft_mag):\n",
    "    power = np.square(fft_mag)\n",
    "    return power\n",
    "\n",
    "# the only way this comes out is if the slope is made a positive value if negative\n",
    "def compute_fd(slope):\n",
    "    fd = (5 - abs(slope)) / 2\n",
    "    return fd\n",
    "\n",
    "# FD function\n",
    "def compute_fd_from_signal(s, fs, min_f, max_f):\n",
    "    # apply hanning window\n",
    "    hann = apply_hanning(s)\n",
    "    dft_result = np.fft.fft(hann)\n",
    "\n",
    "    # psd\n",
    "    x_f = np.fft.fftfreq(len(hann), d=1/fs)\n",
    "    psd = np.abs(dft_result) ** 2\n",
    "    mask = x_f > 0\n",
    "    #postive side of FFT / PSD\n",
    "    pos_f = x_f[mask]\n",
    "    pos_psd = psd[mask]  # Filter PSD using the same mask\n",
    "\n",
    "    # log log\n",
    "    log_f = np.log(pos_f)\n",
    "    log_psd = np.log(pos_psd)\n",
    "\n",
    "    # slope and best fit\n",
    "    indices = np.where((pos_f >= min_f) & (pos_f <= max_f))[0]\n",
    "\n",
    "    x = log_f[indices]\n",
    "    y = log_psd[indices]\n",
    "    m, b, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "    #fractal dimension\n",
    "    fd_n = compute_fd(m)\n",
    "    return fd_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc6288ee-cc4a-4304-a117-e1c020243ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7302725143270978\n",
      "1.7302725143270978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# store a bunch of stuff\n",
    "n_pwr = []\n",
    "n_pwr_freqs = []\n",
    "p_pwr = []\n",
    "p_pwr_freqs = []\n",
    "n_log = []\n",
    "p_log = []\n",
    "n_best_fit = []\n",
    "p_best_fit = []\n",
    "n_slope = []\n",
    "p_slope = []\n",
    "\n",
    "n_norm_fd = []\n",
    "p_norm_fd = []\n",
    "\n",
    "# all FD features\n",
    "n_fd_features = []\n",
    "p_fd_features = []\n",
    "\n",
    "# normal resampled, filtered data - healthy\n",
    "for i, d_set in enumerate(n_norm_res):\n",
    "\n",
    "    if(i==0):\n",
    "        fd_test = compute_fd_from_signal(d_set, fs, 10,300) # extension\n",
    "        print(fd_test)\n",
    "\n",
    "    # compute main FD feature here so that we can store all the parts of it\n",
    "    # apply hanning window\n",
    "    n_hann = apply_hanning(d_set)\n",
    "    dft_result = np.fft.fft(n_hann)\n",
    "\n",
    "    # psd\n",
    "    x_f = np.fft.fftfreq(len(n_hann), d=1/fs)\n",
    "    psd = np.abs(dft_result) ** 2\n",
    "    mask = x_f > 0\n",
    "    #postive side of FFT / PSD\n",
    "    pos_f_n = x_f[mask]\n",
    "\n",
    "    pos_psd_n = psd[mask]  # Filter PSD using the same mask\n",
    "\n",
    "    # log log\n",
    "    log_f_n = np.log(pos_f_n)\n",
    "    log_psd_n = np.log(pos_psd_n)\n",
    "\n",
    "    # slope and best fit\n",
    "    indices = np.where((pos_f_n >= 10) & (pos_f_n <= 300))[0]\n",
    "\n",
    "    x = log_f_n[indices]\n",
    "    y = log_psd_n[indices]\n",
    "    m, b, r_value, p_value, std_err = linregress(x, y)\n",
    "    fit = m*x+b\n",
    "\n",
    "    #fractal dimension\n",
    "    fd_n = compute_fd(m)\n",
    "    if(i==0):\n",
    "        print(fd_n)\n",
    "\n",
    "    # fd1, fd2 - EXT / FLEX\n",
    "    ext_flex = split_signal(d_set)  # ext is 0 and flex is 1\n",
    "    FD1_ext = compute_fd_from_signal(ext_flex[0], fs, 10, 400) # extension\n",
    "    FD2_flex = compute_fd_from_signal(ext_flex[1], fs, 10, 400) # flexion\n",
    "\n",
    "    ext_quarters = split_signal(ext_flex[0])\n",
    "    FD1_ext_q1 = compute_fd_from_signal(ext_quarters[0],fs, 10,400)\n",
    "    FD1_ext_q2 = compute_fd_from_signal(ext_quarters[1],fs, 10, 400)\n",
    "\n",
    "    flex_quarters = split_signal(ext_flex[1])\n",
    "    FD2_flex_q1 = compute_fd_from_signal(flex_quarters[0],fs, 10, 400)\n",
    "    FD2_flex_q2 = compute_fd_from_signal(flex_quarters[1], fs, 10, 400)\n",
    "\n",
    "    n_fd_features.append([fd_n, FD1_ext, FD1_ext_q1, FD1_ext_q2, FD2_flex, FD2_flex_q1, FD2_flex_q2 ])\n",
    "\n",
    "    # store the computations\n",
    "    n_pwr_freqs.append(x)\n",
    "    n_pwr.append(psd)\n",
    "    n_log.append([log_f_n, log_psd_n])\n",
    "    n_slope.append(m)\n",
    "    n_best_fit.append([log_f_n[indices], fit])\n",
    "    n_norm_fd.append(fd_n)\n",
    "\n",
    "for d_set in p_norm_res:\n",
    "\n",
    "    p_hann = apply_hanning(d_set)\n",
    "    dft_result = np.fft.fft(p_hann)\n",
    "    x_f = np.fft.fftfreq(len(p_hann), d=1/fs)\n",
    "    psd = np.abs(dft_result) ** 2\n",
    "    #postive side of FFT / PSD\n",
    "    mask = x_f > 0\n",
    "    # Apply the mask to both frequencies and PSD to ensure they are aligned\n",
    "    pos_f_p = x_f[mask]\n",
    "    pos_psd_p = psd[mask]  # Filter PSD using the same mask\n",
    "    # log - log\n",
    "    log_f_p = np.log(pos_f_p)\n",
    "    log_psd_p = np.log(pos_psd_p)\n",
    "\n",
    "    indices = np.where((pos_f_p >= 10) & (pos_f_p <= 300))[0]\n",
    "    x = log_f_p[indices]\n",
    "    y = log_psd_p[indices]\n",
    "    m, b, r_value, p_value, std_err = linregress(x, y)\n",
    "    fit = m*x+b\n",
    "\n",
    "    #fractal dimension\n",
    "    fd_p = compute_fd(m)\n",
    "\n",
    "     # fd1, fd2 - EXT / FLEX\n",
    "    ext_flex = split_signal(d_set)  # ext is 0 and flex is 1\n",
    "    FD1_ext = compute_fd_from_signal(ext_flex[0], fs, 10, 400) # extension\n",
    "    FD2_flex = compute_fd_from_signal(ext_flex[1], fs, 10, 400) # flexion\n",
    "\n",
    "    ext_quarters = split_signal(ext_flex[0])\n",
    "    FD1_ext_q1 = compute_fd_from_signal(ext_quarters[0],fs, 10, 400)\n",
    "    FD1_ext_q2 = compute_fd_from_signal(ext_quarters[1],fs, 10, 400)\n",
    "\n",
    "    flex_quarters = split_signal(ext_flex[1])\n",
    "    FD2_flex_q1 = compute_fd_from_signal(flex_quarters[0],fs, 10, 400)\n",
    "    FD2_flex_q2 = compute_fd_from_signal(flex_quarters[1], fs, 10, 400)\n",
    "\n",
    "    p_fd_features.append([fd_p, FD1_ext, FD1_ext_q1, FD1_ext_q2, FD2_flex, FD2_flex_q1, FD2_flex_q2 ])\n",
    "    \n",
    "    p_pwr_freqs.append(x_f)\n",
    "    p_pwr.append(psd)\n",
    "    p_log.append([log_f_p, log_psd_p])\n",
    "    p_slope.append(m)\n",
    "    p_best_fit.append([log_f_p[indices], fit])\n",
    "    p_norm_fd.append(fd_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fa9a750-94fd-403f-8e9d-639133f7dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df_feature_set csv \n",
    "df = pd.DataFrame()\n",
    "\n",
    "# class\n",
    "n_class = np.ones(len(n_fd_features),dtype=int)\n",
    "p_class = np.zeros(len(p_fd_features), dtype=int)\n",
    "feature_class = np.concatenate((n_class, p_class))\n",
    "df[\"class\"] = feature_class\n",
    "\n",
    "keys = [\"FD\", \"FD1_ext\", \"FD1_ext_q1\", \"FD1_ext_q2\", \"FD2_flex\", \"FD2_flex_q1\", \"FD2_flex_q2\"]\n",
    "\n",
    "for i in range(0, len(keys)):\n",
    "    feature_n = np.array([lst[i] for lst in n_fd_features])\n",
    "    feature_p = np.array([lst[i] for lst in p_fd_features])\n",
    "    feature_concat = np.concatenate((feature_n, feature_p))\n",
    "    feature_key = keys[i]\n",
    "    df[feature_key] = feature_concat\n",
    "\n",
    "# write to csv\n",
    "directory = 'ML/features'\n",
    "file_name = f'vag_fd_features.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to avoid writing row indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dd53a-1a7a-412c-a399-01364ec284d6",
   "metadata": {},
   "source": [
    "The best method available to estimate the FD of a self-affine signal is PSA. As explained in Section 1.1, an fBm signal has a PSD that\n",
    "follows the 1/f model. A high value of ˇ indicates a rapid decrease\n",
    "in the high-frequency content of the signal. A self-affine fBm function in an E-dimensional Euclidean space has its PSD PV(f) ∝ 1/f\n",
    "with\n",
    "\n",
    "FD = E + 1 − H\n",
    "H = B - 1 /2\n",
    "\n",
    "FD = E + 1 - ((B-1)/2))\n",
    "\n",
    "If E = 1\n",
    "\n",
    "FD = 5-B / 2\n",
    "\n",
    "the average and standard deviation values of FD for the 51 normal signals were 1.8061 ± 0.2398;\n",
    "those for the 38 abnormal VAG signals were 1.6695 ± 0.2226 (using the frequency range [10, 300] Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9c624e-d892-4a7d-a53d-5fef55ee0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'healthy': {'FD': {'mean': 1.8597, 'std': 0.2264}, 'FD1_ext': {'mean': 1.9185, 'std': 0.2927}, 'FD1_ext_q1': {'mean': 1.9919, 'std': 0.207}, 'FD1_ext_q2': {'mean': 1.9043, 'std': 0.2359}, 'FD2_flex': {'mean': 1.93, 'std': 0.2364}, 'FD2_flex_q1': {'mean': 1.8558, 'std': 0.2562}, 'FD2_flex_q2': {'mean': 2.0651, 'std': 0.1511}}, 'pathology': {'FD': {'mean': 1.7265, 'std': 0.2189}, 'FD1_ext': {'mean': 1.8197, 'std': 0.2088}, 'FD1_ext_q1': {'mean': 1.9008, 'std': 0.2091}, 'FD1_ext_q2': {'mean': 1.7089, 'std': 0.2203}, 'FD2_flex': {'mean': 1.8319, 'std': 0.251}, 'FD2_flex_q1': {'mean': 1.7523, 'std': 0.2368}, 'FD2_flex_q2': {'mean': 1.9097, 'std': 0.2231}}, 'p_values': {'FD': 0.0072, 'FD1_ext': 0.0832, 'FD1_ext_q1': 0.0461, 'FD1_ext_q2': 0.0002, 'FD2_flex': 0.0658, 'FD2_flex_q1': 0.0575, 'FD2_flex_q2': 0.0002}}\n",
      "\n",
      "{'FD': 0.0072, 'FD1_ext': 0.0832, 'FD1_ext_q1': 0.0461, 'FD1_ext_q2': 0.0002, 'FD2_flex': 0.0658, 'FD2_flex_q1': 0.0575, 'FD2_flex_q2': 0.0002}\n"
     ]
    }
   ],
   "source": [
    "# compute statistics for the each feature\n",
    "#[fd_p, FD1_ext, FD1_ext_q1, FD1_ext_q2, FD2_flex, FD2_flex_q1, FD2_flex_q2 ]\n",
    "\n",
    "vag_fd_stats = {\n",
    "    \"healthy\":{},\n",
    "    \"pathology\": {},\n",
    "    \"p_values\":{},\n",
    "}\n",
    "\n",
    "keys = [\"FD\", \"FD1_ext\", \"FD1_ext_q1\", \"FD1_ext_q2\", \"FD2_flex\", \"FD2_flex_q1\", \"FD2_flex_q2\"]\n",
    "\n",
    "for i in range(0, len(keys)):\n",
    "    feature_n = np.array([lst[i] for lst in n_fd_features])\n",
    "    feature_p = np.array([lst[i] for lst in p_fd_features])\n",
    "    feature_key = keys[i]\n",
    "\n",
    "    feature_mean_n = round(np.mean(feature_n),4)\n",
    "    feature_std_n  =  round(np.std(feature_n),4)\n",
    "    feature_mean_p = round(np.mean(feature_p),4)\n",
    "    feature_std_p  =  round(np.std(feature_p),4)\n",
    "\n",
    "    t, p_value = stats.ttest_ind(feature_n, feature_p)\n",
    "    \n",
    "    vag_fd_stats[\"healthy\"][feature_key] = {\n",
    "        \"mean\": feature_mean_n,\n",
    "        \"std\": feature_std_n,\n",
    "    }\n",
    "\n",
    "    vag_fd_stats[\"pathology\"][feature_key] = {\n",
    "        \"mean\": feature_mean_p,\n",
    "        \"std\": feature_std_p,\n",
    "    }\n",
    "\n",
    "    vag_fd_stats[\"p_values\"][feature_key] = round(p_value,4)\n",
    "    \n",
    "print(vag_fd_stats)\n",
    "print()\n",
    "print(vag_fd_stats[\"p_values\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3de86-71bb-4e50-ba45-e32f4622bdcd",
   "metadata": {},
   "source": [
    "- FD 0.0075\n",
    "- FD1h 0.0850 extension\n",
    "- FD2h 0.0573 flexion\n",
    "- FD1q 0.0222 extension\n",
    "- FD2q 0.0001 extension\n",
    "- FD3q 0.0813 flexion\n",
    "- FD4q 0.0003 flexion\n",
    "\n",
    "It is evident from the p-values that the differences between the values of FD, FD2q, and FD4q are statistically highly signiﬁcant (p < 0.01)\n",
    "(FD, FD1_ext_q2, FD2_flex_q2) - 0.0072, 0.0002, 0.0002\n",
    "\n",
    "whereas the differences in the FD1q values for the normal and\n",
    "abnormal categories are statistically signiﬁcant (0.01 < p < 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9878189-70a9-46cc-8c5a-541443a2baa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
